# Custom Neural Network Implementation

This project provides a custom implementation of a neural network in Python, including essential components like layers, activation functions, loss functions, and optimization techniques. It supports forward and backward propagation with custom initializers and multiple optimization methods, such as Gradient Descent. The framework is designed with flexibility and scalability in mind, allowing easy customization and extension of various layers and optimizers.

## Key Features:
- **Neural Network Architecture**: Define and train a neural network with custom layers, activations, and loss functions.
- **Layer Types**: Includes fully connected layers, ReLU, and Sigmoid activation functions.
- **Loss Functions**: Supports binary cross-entropy (BCELoss) for binary classification tasks.
- **Optimization**: Implements Gradient Descent for model parameter updates.
- **Custom Initialization**: Choose from random or He initialization for weights.

This is a foundational project for building and experimenting with neural networks from scratch.

